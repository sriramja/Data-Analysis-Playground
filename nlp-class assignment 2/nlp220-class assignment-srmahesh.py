# -*- coding: utf-8 -*-
"""Untitled27.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BMwmVF-42Z8K_BcMC5ir7ht7a03wFYr6
"""

# Load the Sentiment Treebank dataset and analyze it using Python.

import csv

txt_dict = r"sentiment_labels.txt"
txt2_dict = r"dictionary.txt"
csv_dict = r"sentiment_labels.csv"
csv2_dict = r"dictionary.csv"

in_txt = csv.reader(open(txt_dict, "r"), delimiter = '|')
out_csv = csv.writer(open(csv_dict, 'w'))
out_csv.writerows(in_txt)

in2_txt = csv.reader(open(txt2_dict, "r"), delimiter = '|')
out2_csv = csv.writer(open(csv2_dict, 'w'))
out2_csv.writerows(in2_txt)

# Print all phrases which are annotated with  sentiment score between 0.1 and 0.2 (including).

import pandas as pd

csv_file_list = ["sentiment_labels.csv", "dictionary.csv"]
df1 = pd.read_csv("sentiment_labels.csv")
df2 = pd.read_csv("dictionary.csv")

for i in range(0,len(df1["sentiment values"])):
  if df1["sentiment values"][i]>=0.1 and df1["sentiment values"][i]<=0.2:
    print(df2["!"][i])

# Print all the phrases which are most negative (sentiment score between 0.1 and 0.5) and contain at least 2 tokens.

for i in range(0,len(df1["sentiment values"])):
  if df1["sentiment values"][i]>0.1 and df1["sentiment values"][i]<0.5 and (len(df2["!"][i]) > 2):
    print(df2["!"][i])

# Print all phrases that contain any of the following words: “love”, “like”, “hate”.

phrase = ["love", "like", "hate"]

for i in range(0,len(df1["sentiment values"])):

  if any(substring in df2["!"][i] for substring in phrase):
    print(df2["!"][i])

# Print all phrases where the word “like” is present but it is not a verb.

import nltk
from nltk.tokenize import word_tokenize
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

for i in range(0,len(df1["sentiment values"])):
  if 'like' in df2["!"][i]:
    text = word_tokenize(df2["!"][i])
    for j in nltk.pos_tag(text):
      if j[1] == 'VB':
        print(df2["!"][i])

